---
layout: page
title: Research
---

<head>
  <title>Research overview</title>

  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]} });
  </script>
  
  <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>
  
  <style>
	.project-title {
	  font-size: 20px;
	  display:inline-block;vertical-align:top;
	}
  </style>
  
</head>
<body>

The overarching objective of my research work is to establish provable safety guarantees for autonomous systems. 
During my PhD I focused on establishing safety guarantees for systems losing control over some of their actuators, which led to my resilience framework discussed below.
As a postdoctoral scholar I am interested in ensuring safety for black-box systems relying on reinforcement learning and diffusion.

  <hr style="margin-top:1cm;">
  <h2>Guaranteeing Safety in Reinforcement Learning</h2>
  
  <p>
    My most recent research topic is to develop provable safety guarantees in Reinforcement Learning (RL).
	More specifically, I have been looking at enforcing hard constraints with a learned policy in closed-loop with a black-box environment.
	In <a href="{{ site.baseurl }}/assets/blog_posts/safe_RL" target="_blank" rel="noopener noreferrer">this blog post</a> I discuss how most of the safe RL literature <em>cannot guarantee such constraint respect</em>.
	Based on this observation, I devised <strong>POLICEd RL</strong> to solve this issue.
  </p>
  <p>
	The main idea for POLICEd RL is to make the policy repulsive in the state-space region surrounding the constraint.
	This repulsive buffer will then push trajectories away from the constraint and guarantee its satisfaction.
	The policy learns to be repulsive as it receives penalties for each constraint violation during training.
	My key insight is to use the <a href="https://ieeexplore.ieee.org/document/10096520" target="_blank" rel="noopener noreferrer">POLICE algorithm</a>
	to make the policy affine in this buffer, which then allows to verify its repulsive character by only evaluating the policy at the vertices of the buffer.
	This discrete and small number of evaluations to <em>guarantee safety</em> contrasts with the typical approach of learning a safety certificate that needs to be
	evaluated <em>everywhere on the state space</em> to check if this learned certificate verifies the analytical safety conditions.
  </p>
  <p>
	We illustrate POLICEd RL below on a simple 2D system and show that safety is guaranteed at the end of training.
	Without the affine policy, TD3 requires several orders of magnitude more training episodes to learn a policy pointing away from the constraint line on its whole length.
	For more details the POLICEd RL paper is accessible <a href="{{ site.baseurl }}/assets/PDFs/POLICEd_RL_ArXiv.pdf" target="_blank" rel="noopener noreferrer">here</a>.
  </p>
	<img src="{{site.baseurl}}/assets/gifs/POLICEd_2D_gif.gif" alt="animated" class="center_img"/> 
	<div class="caption">
		Training of a policy to direct trajectories toward the target (cyan) whithout crossing the constraint line (red).<br>
		The POLICEd policy is affine in the buffer region (green) and learns to push trajectories away from the constraint.
		The black-box dynamics are 2D and continuous, the RL algorithm is TD3.<br>
	</div>	

  
  
  
  
  <hr style="margin-top:1cm;">
  <h2>Resilience of Autonomous Systems</h2>
  
  <p>
	After docking to the International Space Station (ISS), the Nauka module suffered a software error causing its thrusters to misfire.
	In turn, these uncontrolled thrusters rotated the whole space station by 540° before being counteracted by other thrusters of the ISS.
	Motivated by such a scenario, my PhD thesis investigated the guaranteed resilience of autonomous systems to a similar class of malfunctions called partial loss of control authority over actuators.
	These malfunctions are characterized by actuators producing uncontrolled and undesirable outputs instead of following the controller’s commands.
	A loss of control authority can be caused, for instance, by a software bug as in the ISS example or by an adversarial takeover of some actuators of the system.
  </p>
  <p>  
	In this setting, I investigated the malfunctioning system's remaining capabilities to complete its mission in terms of resilient reachability and resilient trajectory tracking.
	I quantified the resilience of linear systems by comparing the reachability performance of the nominal dynamics with that of the worst-case malfunctioning dynamics.
	The resilience of driftless systems is quantified by the Maximax Minimax Quotient Theorem whose geometrical proof is illustrated on the video below.
  </p>	
	 
   <div class="videowrapper">
     <iframe src="https://www.youtube.com/embed/rjKzHyDJX40">
     </iframe>
   </div>
	
  <p>	
	I extended my resilience investigation to systems further inflicted with actuation delays preventing an immediate cancellation of the undesirable outputs.
	I illustrated my theory on a wide range of applications including an octocopter, a fighter jet model, and an orbital inspection mission illustrated by the following video.
  </p>

  <div class="videowrapper">
    <iframe src="https://www.youtube.com/embed/DQy8iNHyt7M">
	</iframe>
  </div>
  
  <p>
	For more details on resilience theory see <a href="{{ site.baseurl }}/assets/blog_posts/resilience">this blog post</a>.
  </p>




  <hr style="margin-top:1cm;">
  <h2>Astrodynamics work</h2>
  
  



  
  <hr style="margin-top:1cm;">
  <h2>Other Research Work</h2>
  
  
  <details>
    <summary>
      <div class="project-title">Transient Safety of Microgrids</div>
	  <div class="github-link">
        <a href="https://github.com/Jean-BaptisteBouvier/Microgrid-transient-safety" target="_blank" rel="noopener noreferrer"><img src="{{site.baseurl}}/assets/logos/GitHub_logo.png" width="25"></a>
      </div>
	</summary>
    <ul>
      <li>To ensure transient safety in inverter-based microgrids, we develop a set invariance-based distributed safety verification algorithm for each inverter module.
	  Applying Nagumo’s invariance condition, we construct a robust polynomial optimization problem to jointly search for safety-admissible set of control set-points and design parameters,
	  under allowable disturbances from neighbors.
	  We use sum-of-squares (SOS) programming to solve the verification problem and we perform numerical simulations using grid-forming inverters to illustrate the algorithm.</li>
      <li>This work has first been presented at the <a href="https://ieeexplore.ieee.org/document/9867323" target="_blank" rel="noopener noreferrer">2022 American Control Conference</a>.</li>
    </ul>

  </details>
  
  
  
  
  
  
<!-- Code to add a button return to top -->
<button onclick="topFunction()" id="topBtn" title="Go to top">Top</button>
<script src="{{ site.baseurl }}/assets/js/top_button.js" ></script>

  
</body>  

